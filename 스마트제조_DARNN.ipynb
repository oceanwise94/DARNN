{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "스마트제조_DARNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LevF-ohsCbXOvPd6VUMhWmh4IueBEDgS",
      "authorship_tag": "ABX9TyPhO4p68HGRknUjl9xGoqNg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oceanwise94/DARNN/blob/master/%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%A0%9C%EC%A1%B0_DARNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUrNX9j2DNVH"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib import rc\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLrIx47CCQ2A"
      },
      "source": [
        "os.chdir(r\"/content/drive/MyDrive/1.모델링자료/0.샘플데이터/회귀/시계열/스마트제조\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztU1nRJgCUon"
      },
      "source": [
        "data = pd.read_excel(\"Dataset_temp 90.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT2mNK8lC83e"
      },
      "source": [
        "data = data.drop(['Time stamp','Predicted Diameter\\nDiameter (mm)','Target Velocity\\nSpool Rev/Sec'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmBffrNYGgs2"
      },
      "source": [
        "data.columns = ['x1','x2','y']\n",
        "basic_columns = data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhflZnTEYO-"
      },
      "source": [
        "for x in ['x1','x2']:\n",
        "    mean, std = data.agg([\"mean\", \"std\"]).loc[:, x]\n",
        "    data[x] = (data[x] - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4aB938vVCdw"
      },
      "source": [
        "data_x = data.loc[:, \"x1\":\"x2\"]\n",
        "data_y = data.loc[:, \"y\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku2xHWSqG534"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCgJkH6CE-S2"
      },
      "source": [
        "# RNN 모델에 입력 할 수 있는 시계열 형태로 데이터 변환\n",
        "# sequence 길이 5\n",
        "interval = 5\n",
        "encoder_list = []\n",
        "decoder_list = []\n",
        "target_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nVrjyp9HC92"
      },
      "source": [
        "interval = 5\n",
        "encoder_list = []\n",
        "decoder_list = []\n",
        "target_list = []\n",
        "for i in range(1, data_x.shape[0] - interval):\n",
        "    encoder_list.append(np.array(data_x.iloc[i : i + interval]))\n",
        "    decoder_list.append(np.array(data_y.iloc[i : i + interval - 1]))\n",
        "    target_list.append(data_y.iloc[i + interval])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abalJbvMH4_2"
      },
      "source": [
        "encoder_sequence = np.array(encoder_list)\n",
        "decoder_sequence = np.array(decoder_list)\n",
        "decoder_sequence = np.reshape(decoder_sequence, (-1, 4, 1))\n",
        "target = np.array(target_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1lAar7YI7PO"
      },
      "source": [
        "T = 5\n",
        "m = 32\n",
        "p = 32\n",
        "train_num = 794 # 200개 test\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwlXbk00JXKH"
      },
      "source": [
        "enc_data = encoder_sequence\n",
        "dec_data = decoder_sequence\n",
        "target = target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dt3BXBeJiHu"
      },
      "source": [
        "enc_data.shape, dec_data.shape, target.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM8hK6x2Jjxn"
      },
      "source": [
        "class Encoderlstm(Layer):\n",
        "    def __init__(self,m):\n",
        "        '''\n",
        "        m : lstm features num\n",
        "        '''\n",
        "        super(Encoderlstm,self).__init__(name='encoder_lstm')\n",
        "        self.lstm = LSTM(m, return_state=True)\n",
        "        self.initial_state = None\n",
        "\n",
        "    def call(self,x, training=False):\n",
        "        '''\n",
        "        x : t번째 input data (shape = batch,1,n)\n",
        "        '''\n",
        "        h_s, _, c_s = self.lstm(x,initial_state = self.initial_state)\n",
        "        self.initial_state = [h_s,c_s]\n",
        "        return h_s,c_s\n",
        "    \n",
        "    def reset_state(self, h0, c0):\n",
        "        self.initial_state = [h0,c0]\n",
        "\n",
        "class InputAttention(Layer):\n",
        "    def __init__(self,T):\n",
        "        super(InputAttention,self).__init__(name = \"input_attention\")\n",
        "        self.w1 = Dense(T)\n",
        "        self.w2 = Dense(T)\n",
        "        self.v = Dense(1)\n",
        "\n",
        "    def call(self, h_s, c_s, x):\n",
        "        \"\"\"\n",
        "        h_s : hidden_state shape = batch, m\n",
        "        c_s : cell_state shape = batch,m\n",
        "        x : time series encoder inputs shape = batch,T,n\n",
        "        \"\"\"\n",
        "        query = tf.concat([h_s,c_s],axis=-1) # batch,m*2\n",
        "        query = RepeatVector(x.shape[2])(query) # batch,n,m*2\n",
        "        x_perm = Permute((2,1))(x) # batch,n,T\n",
        "        score = tf.nn.tanh(self.w1(x_perm) + self.w2(query)) # batch,n,T\n",
        "        score = self.v(score) # batch,n,1\n",
        "        score = Permute((2,1))(score) # batch,1,n\n",
        "        attention_weigths = tf.nn.softmax(score) # t번째 time step일 때 각 feature별 중요도\n",
        "        return attention_weigths\n",
        "\n",
        "\n",
        "class Encoder(Layer):\n",
        "    def __init__(self,T,m):\n",
        "        super(Encoder,self).__init__(name = 'encoder')\n",
        "        self.T = T\n",
        "        self.input_att = InputAttention(T)\n",
        "        self.lstm = Encoderlstm(m)\n",
        "        self.alpha_t = None\n",
        "    \n",
        "    def call(self,data,h0,c0,n=2,training=False):\n",
        "        '''\n",
        "        data : encoder data (shape = batch,T,n)\n",
        "        n : data features num\n",
        "        '''\n",
        "        self.lstm.reset_state(h0=h0,c0=c0)\n",
        "        alpha_seq = tf.TensorArray(tf.float32,self.T)\n",
        "        for t in range(self.T):\n",
        "            x = Lambda(lambda x:data[:,t,:])(data) # batch,n\n",
        "            x = x[:,tf.newaxis,:] # batch,1,n\n",
        "            h_s,c_s = self.lstm(x)\n",
        "            self.alpha_t = self.input_att(h_s,c_s,data) # batch,1,n\n",
        "            alpha_seq = alpha_seq.write(t, self.alpha_t)\n",
        "        alpha_seq = tf.reshape(alpha_seq.stack(), (-1,self.T,n)) # batch,T,n\n",
        "        output = tf.multiply(data,alpha_seq) # batch,T,n\n",
        "        return output\n",
        "\n",
        "class Decoderlstm(Layer):\n",
        "    def __init__(self,p):\n",
        "        '''\n",
        "        p : decoder lstm feature dim\n",
        "        '''\n",
        "        super(Decoderlstm,self).__init__(name = 'decoder_lstm')\n",
        "        self.lstm = LSTM(p, return_state=True)\n",
        "        self.initial_state = None\n",
        "    \n",
        "    def call(self,x,training=False):\n",
        "        '''\n",
        "        x. : t번째 input data (shape = batch,1,1)\n",
        "        '''\n",
        "        h_s,_,c_s = self.lstm(x,initial_state = self.initial_state)\n",
        "        self.initial_state = [h_s,c_s]\n",
        "        return h_s,c_s\n",
        "\n",
        "    def reset_state(self,h0,c0):\n",
        "        self.initial_state = [h0,c0]\n",
        "\n",
        "\n",
        "class TemporalAttention(Layer):\n",
        "    def __init__(self, m):\n",
        "        super(TemporalAttention, self).__init__(name = 'temporal_attention')\n",
        "        self.w1 = Dense(m)\n",
        "        self.w2 = Dense(m)\n",
        "        self.v = Dense(1)\n",
        "\n",
        "    def call(self,h_s,c_s,enc_h):\n",
        "        '''\n",
        "        h_s : decoder hidden state : shape = batch,p\n",
        "        c_s : decodercell state : shape = batch,p\n",
        "        enc_h : shape = batch,T,m\n",
        "        '''\n",
        "        query = tf.concat([h_s,c_s],axis=-1) # batch, 2*p\n",
        "        query = RepeatVector(enc_h.shape[1])(query) # batch, T, 2*p\n",
        "        score = tf.nn.tanh(self.w1(enc_h) + self.w2(query)) # batch, T, m\n",
        "        score = self.v(score)\n",
        "        attention_weights = tf.nn.softmax(score, axis = 1) # encoder hidden state h(i)의 중요성을 나타낸다. (0<=i<=T)\n",
        "        return attention_weights\n",
        "\n",
        "\n",
        "class Decoder(Layer):\n",
        "    def __init__(self,T,p,m):\n",
        "        super(Decoder,self).__init__(name = 'decoder')\n",
        "        self.T = T\n",
        "        self.temp_att = TemporalAttention(m)\n",
        "        self.dense = Dense(1)\n",
        "        self.lstm = Decoderlstm(p)\n",
        "        self.enc_lstm_dim = m\n",
        "        self.dec_lstm_dim = p\n",
        "        self.context_v = None\n",
        "        self.dec_h_s = None\n",
        "        self.beta_t = None\n",
        "    \n",
        "    def call(self,data,enc_h,h0 = None, c0 = None, training=False):\n",
        "        '''\n",
        "        data : decoder data (shape = batch,T-1,1)\n",
        "        enc_h : encoder hidden state (shape = batch,T,m)\n",
        "        '''\n",
        "        self.lstm.reset_state(h0=h0,c0=c0)\n",
        "        self.context_v = tf.zeros((tf.shape(enc_h)[0],1,self.enc_lstm_dim)) # batch,1,m+!\n",
        "        for t in range(self.T-1):\n",
        "            x = Lambda(lambda x: data[:,t,:])(data) # batch,1\n",
        "            x = x[:,tf.newaxis,:] # batch,1,1\n",
        "            x = tf.concat([x,self.context_v],axis=-1) # batch, 1, m+1\n",
        "            x = self.dense(x) # batch, 1, 1\n",
        "            h_s,c_s = self.lstm(x) # batch,p\n",
        "            self.beta_t = self.temp_att(h_s,c_s,enc_h) # batch, T, 1\n",
        "            self.context_v = tf.matmul(self.beta_t,enc_h,transpose_a=True) # batch,1,m\n",
        "        \n",
        "        return tf.concat([h_s[:,tf.newaxis,:],self.context_v],axis=-1) # batch,1,m+p\n",
        "\n",
        "\n",
        "class DARNN(Model):\n",
        "    def __init__(self,T,m,p):\n",
        "        super(DARNN,self).__init__(name = 'DARNN')\n",
        "        '''\n",
        "        T : sequence 길이\n",
        "        m : encoder lstm features\n",
        "        p : decoder lstm features\n",
        "        '''\n",
        "        self.m = m\n",
        "        self.encoder = Encoder(T=T, m=m)\n",
        "        self.decoder = Decoder(T = T,p=p,m=m)\n",
        "        self.lstm = LSTM(m,return_sequences=True)\n",
        "        self.dense1 = Dense(p)\n",
        "        self.dense2 = Dense(1)\n",
        "    \n",
        "    def call(self,inputs, training=False, mask=None):\n",
        "        '''\n",
        "        inputs : [enc,dec]\n",
        "        enc_data : batch,T,n\n",
        "        dec_data : batch,T-1,1\n",
        "        '''\n",
        "        enc_data, dec_data = inputs\n",
        "        batch = tf.shape(enc_data)[0]\n",
        "        h0 = tf.zeros((batch,self.m))\n",
        "        c0 = tf.zeros((batch,self.m))\n",
        "        enc_output = self.encoder(enc_data,  n=2, h0=h0, c0=c0,training=training) # batch,T,n\n",
        "        enc_h = self.lstm(enc_output) # batch,T,m\n",
        "        dec_output = self.decoder(dec_data,enc_h,h0=h0,c0=c0, training=training) # batch, 1, m+p\n",
        "        output = self.dense2(self.dense1(dec_output)) # batch, 1, 1\n",
        "        output = tf.squeeze(output) # batch\n",
        "        return output\n",
        "\n",
        "model = DARNN(T=T,m=m,p=p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah-HfDkUJnue"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((enc_data[:train_num],dec_data[:train_num],target[:train_num])).batch(batch_size).shuffle(buffer_size=train_num).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model,inputs,labels,loss_fn,optimizer,train_loss):\n",
        "    with tf.GradientTape() as tape:\n",
        "        prediction = model(inputs,training=True)\n",
        "        loss = loss_fn(labels,prediction)\n",
        "    gradients = tape.gradient(loss,model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "\n",
        "loss_fn = tf.keras.losses.MSE\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
        "\n",
        "for epoch in range(100):\n",
        "    for enc,dec,label in train_ds:\n",
        "        inputs = [enc,dec]\n",
        "        train_step(model,inputs,label,loss_fn,optimizer,train_loss)\n",
        "    \n",
        "    print(f\"epoch : {epoch+1}, train_loss : {train_loss.result()}\")\n",
        "    train_loss.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orcFkPeSTLb6"
      },
      "source": [
        "test_ds = tf.data.Dataset.from_tensor_slices((enc_data[train_num:], dec_data[train_num:], target[train_num:])).batch(16)\n",
        "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
        "\n",
        "@tf.function\n",
        "def test_step(model,inputs,labels,loss_fn,test_loss):\n",
        "    prediction = model(inputs,training=True)\n",
        "    loss = loss_fn(labels,prediction)\n",
        "    test_loss(loss)\n",
        "    return prediction\n",
        "\n",
        "i=0\n",
        "for enc,dec,label in test_ds:\n",
        "    inputs = [enc,dec]\n",
        "    pred = test_step(model,inputs,label,loss_fn,test_loss)\n",
        "    if i==0:\n",
        "        preds = pred.numpy()\n",
        "        labels = label.numpy()\n",
        "        i+=1\n",
        "    else:\n",
        "        preds = np.concatenate([preds, pred.numpy()],axis=0)\n",
        "        labels = np.concatenate([labels,label.numpy()],axis=0)\n",
        "\n",
        "print(test_loss.result())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9SqURRhfoAk"
      },
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (12,12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntloa6gLJ0Ge"
      },
      "source": [
        "preds = np.array(preds)\n",
        "labels = np.array(labels)\n",
        "plt.scatter(preds,labels,color = 'orange')\n",
        "plt.xlabel(\"pred\")\n",
        "plt.ylabel(\"label\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TCc5kZ6WBcm"
      },
      "source": [
        "enc,dec,label = next(iter(test_ds))\n",
        "inputs = [enc, dec]\n",
        "pred = model(inputs)\n",
        "\n",
        "beta = []\n",
        "\n",
        "for i in range(5):\n",
        "    beta.append(np.mean(model.decoder.beta_t[:,i,0].numpy()))  # batch, T, 1\n",
        "plt.bar(x = range(5), height=beta, color = 'orange')\n",
        "plt.title(\"Beta\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"prob\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAOL9vOdWIC2"
      },
      "source": [
        "%matplotlib\n",
        "variables = ['x1','x2']\n",
        "alpha = []\n",
        "for i in range(2):\n",
        "    alpha.append(np.mean(model.encoder.alpha_t[:,0,i].numpy()))\n",
        "\n",
        "plt.bar(x=variables,height=alpha, color = 'orange')\n",
        "plt.title(\"alpha\")\n",
        "plt.xlabel(\"variables\")\n",
        "plt.xticks(rotation = 90)\n",
        "plt.ylabel(\"prob\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LZM3svufbKm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}